<workflow-app xmlns='uri:oozie:workflow:0.4' name='sparkETL_${sourceTable}'>
	<global>
		<job-tracker>${jobTracker}</job-tracker>
		<name-node>${nameNode}</name-node>
		<configuration>
			<property>
				<name>mapred.job.queue.name</name>
				<value>${queueName}</value>
			</property>
		</configuration>
	</global>

	<start to='spark-shell' />

	<action name='spark-shell'>
		<shell xmlns="uri:oozie:shell-action:0.2">
			<job-tracker>${jobTracker}</job-tracker>
			<name-node>${nameNode}</name-node>
			<configuration>
				<property>
					<name>oozie.launcher.mapreduce.job.queuename</name>
					<value>${launcherQueueName}</value>
				</property>
				<property>
					<name>oozie.action.max.output.data</name>
					<value>70000</value>
				</property>
			</configuration>

			<exec>sparkStarter.sh</exec>

			<argument>${principal}</argument>
			<argument>myproject.jar</argument>
			<argument>svApp</argument>
			<argument>${queueName}</argument>
			<argument>${loading_id}</argument>
			<argument>${deltaMinus}</argument>
			<argument>${sourceUrl}</argument>
			<argument>${sourceUser}</argument>
			<argument>${passwordAliasQa}</argument>
			<argument>${sourceSchema}</argument>
			<argument>${sourceTable}</argument>
			<argument>${replicaSchema}</argument>
			<argument>${replicaTable}</argument>
			<argument>${primaryKeys}</argument>
			<argument>${excludedColumns}</argument>
			<argument>${replicaReader}</argument>
			<argument>${ctlQaEntityId}</argument>
			<argument>${samplePercent}</argument>
			<argument>${jdbcDriver}</argument>
			<argument>${jceksPathQa}</argument>
			<argument>${replicaPartitionDivider}</argument>
			<argument>${summaryGenerator}</argument>

			<file>${keytab}#stork.keytab</file> 
			<capture-output/>
		</shell>

		<ok to="end"/>
		<error to="fail"/>
	</action>

	<kill name="fail">
		<message>Spark Shell Action failed, error message[${wf:errorMessage(wf:lastErrorNode())}]</message>
	</kill>
	<end name="end"/>
</workflow-app>
